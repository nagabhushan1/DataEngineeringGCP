{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e2a9ee2",
   "metadata": {},
   "source": [
    "# Google Cloud Dataproc Cluster Setup for Multi-User Spark Training\n",
    "\n",
    "This notebook contains **step-by-step commands** and explanations to provision a Dataproc cluster that works well for **many concurrent learners running small Spark jobs**. It also includes a brief note on how autoscaling can save costs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4385e56",
   "metadata": {},
   "source": [
    "## ðŸ“Œ What is Google Cloud Dataproc?\n",
    "\n",
    "Google Cloud Dataproc is a **fully managed Apache Spark and Hadoop service**. It provisions clusters quickly, configures components, and integrates with GCS, BigQuery, and other GCP services.\n",
    "\n",
    "**Key features**:\n",
    "- Managed Spark/Hadoop/Hive deployments\n",
    "- Fast cluster startup\n",
    "- Component Gateway (easy access to web UIs like Jupyter, YARN, Spark)\n",
    "- Tight integrations with GCS & BigQuery\n",
    "- Autoscaling support\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9d7c94",
   "metadata": {},
   "source": [
    "## ðŸ“Š Cluster Architecture\n",
    "\n",
    "```\n",
    "                +-----------------------------+\n",
    "                |         Master Node         |\n",
    "                |  e2-standard-4 (4 vCPU)     |\n",
    "                |  Jupyter + Spark Driver     |\n",
    "                +--------------+--------------+\n",
    "                               |\n",
    "          ---------------------------------------------\n",
    "          |            |            |            |\n",
    "+---------+  +---------+  +---------+  +---------+\n",
    "| Worker 1|  | Worker 2|  | Worker 3|  | Worker N|\n",
    "| e2-std-2|  | e2-std-2|  | e2-std-2|  | e2-std-2|\n",
    "| 1 exec  |  | 1 exec  |  | 1 exec  |  | 1 exec  |\n",
    "+---------+  +---------+  +---------+  +---------+\n",
    "     |            |            |            |\n",
    "     -----------------------------------------\n",
    "                    Google Cloud Storage\n",
    "                (Staging & Temporary Buckets)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159665be",
   "metadata": {},
   "source": [
    "## ðŸ›  Steps\n",
    "\n",
    "**All commands below are meant to be run in Google Cloud Shell** (or any machine with the `gcloud` and `gsutil` CLIs authenticated to your project).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b9f486",
   "metadata": {},
   "source": [
    "### 1) Set Project Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7140f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "PROJECT_ID=$(gcloud config get-value project)\n",
    "PROJECT_NUM=$(gcloud projects describe \"$PROJECT_ID\" --format='value(projectNumber)')\n",
    "SA=\"${PROJECT_NUM}-compute@developer.gserviceaccount.com\"\n",
    "echo $PROJECT_ID\n",
    "echo $PROJECT_NUM\n",
    "echo $SA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb58bf4",
   "metadata": {},
   "source": [
    "### 2) Create Staging and Temporary Buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72cc67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gsutil mb -l us-east1 gs://$PROJECT_ID-dp-staging/\n",
    "gsutil mb -l us-east1 gs://$PROJECT_ID-dp-temp/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00698aa",
   "metadata": {},
   "source": [
    "### 3) Grant IAM Permissions to the Service Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506afb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gsutil iam ch serviceAccount:$SA:roles/storage.objectAdmin gs://$PROJECT_ID-dp-staging\n",
    "gsutil iam ch serviceAccount:$SA:roles/storage.objectAdmin gs://$PROJECT_ID-dp-temp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9ec678",
   "metadata": {},
   "source": [
    "### 4) Create the Dataproc Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cc72cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gcloud dataproc clusters create cluster-b533   --region=us-east1   --enable-component-gateway   --no-address   --image-version=2.2-debian12   --master-machine-type=e2-standard-4   --master-boot-disk-type=pd-balanced   --master-boot-disk-size=100   --num-workers=10   --worker-machine-type=e2-standard-2   --worker-boot-disk-type=pd-balanced   --worker-boot-disk-size=40   --bucket=\"$PROJECT_ID-dp-staging\"   --temp-bucket=\"$PROJECT_ID-dp-temp\"   --optional-components=JUPYTER   --scopes='https://www.googleapis.com/auth/cloud-platform'   --properties=\"spark:spark.dynamicAllocation.enabled=false,spark:spark.scheduler.mode=FIFO,spark:spark.executor.instances=1,spark:spark.executor.cores=1,spark:spark.executor.memory=2g,spark:spark.executor.memoryOverhead=512m,spark:spark.driver.memory=1g,spark:spark.driver.memoryOverhead=384m,yarn:yarn.scheduler.minimum-allocation-mb=384,yarn:yarn.scheduler.minimum-allocation-vcores=1,yarn:yarn.scheduler.maximum-allocation-mb=3072,yarn:yarn.scheduler.maximum-allocation-vcores=1\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9b14eb",
   "metadata": {},
   "source": [
    "### 5) Quick runtime validation in Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc78a79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inside Jupyter Notebook on the Dataproc cluster\n",
    "spark.range(1, 1_000_000).count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554daaf6",
   "metadata": {},
   "source": [
    "## ðŸ’¡ How Autoscaling Can Save Costs\n",
    "\n",
    "Autoscaling lets Dataproc **grow** the cluster when many jobs are queued and **shrink** it when idle. This is ideal for training where workloads are **spiky**.\n",
    "\n",
    "Benefits:\n",
    "- Pay only for capacity you use\n",
    "- Faster job starts during spikes\n",
    "- Optionally use **preemptible** workers for cheap burst capacity\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
