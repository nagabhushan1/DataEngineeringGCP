{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e15c58d",
   "metadata": {},
   "source": [
    "# 01 â€” Build Bronze Layer (PySpark on Dataproc, No Hive Required)\n",
    "\n",
    "We **avoid Hive dependencies** by writing **Parquet** datasets under a base path (`GCS_BASE`) and registering **temporary views** for SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be4a8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "spark = SparkSession.builder.appName(\"bronze-dataproc\").getOrCreate()\n",
    "DATA_BASE = os.getenv(\"DATA_BASE\", \"gs://spark-training-pp/etl_spark/raw\")\n",
    "GCS_BASE  = os.getenv(\"GCS_BASE\", \"/user/nb\")\n",
    "print(\"DATA_BASE:\", DATA_BASE); print(\"GCS_BASE:\", GCS_BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56add3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DateType, TimestampType\n",
    "schemas = {\n",
    "    \"crm_cust_info\": [(\"cst_id\",IntegerType()),(\"cst_key\",StringType()),(\"cst_firstname\",StringType()),(\"cst_lastname\",StringType()),(\"cst_marital_status\",StringType()),(\"cst_gndr\",StringType()),(\"cst_create_date\",DateType())],\n",
    "    \"crm_prd_info\": [(\"prd_id\",IntegerType()),(\"prd_key\",StringType()),(\"prd_nm\",StringType()),(\"prd_cost\",IntegerType()),(\"prd_line\",StringType()),(\"prd_start_dt\",TimestampType()),(\"prd_end_dt\",TimestampType())],\n",
    "    \"crm_sales_details\": [(\"sls_ord_num\",StringType()),(\"sls_prd_key\",StringType()),(\"sls_cust_id\",IntegerType()),(\"sls_order_dt\",IntegerType()),(\"sls_ship_dt\",IntegerType()),(\"sls_due_dt\",IntegerType()),(\"sls_sales\",IntegerType()),(\"sls_quantity\",IntegerType()),(\"sls_price\",IntegerType())],\n",
    "    \"erp_loc_a101\": [(\"cid\",StringType()),(\"cntry\",StringType())],\n",
    "    \"erp_cust_az12\": [(\"cid\",StringType()),(\"bdate\",DateType()),(\"gen\",StringType())],\n",
    "    \"erp_px_cat_g1v2\": [(\"id\",StringType()),(\"cat\",StringType()),(\"subcat\",StringType()),(\"maintenance\",StringType())],\n",
    "}\n",
    "def struct_schema(fields):\n",
    "    return StructType([StructField(n,t,True) for n,t in fields])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9e7339",
   "metadata": {},
   "source": [
    "### Dataset: `crm_cust_info`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5668e478",
   "metadata": {},
   "source": [
    "**Intent:** Raw, minimally-typed landing for reproducibility.\n",
    "\n",
    "| Column | Type | Nullable | Description |\n",
    "|---|---|---|---|\n",
    "| `cst_id` | `int` | Yes | Natural numeric ID from CRM; used to join sales |\n",
    "| `cst_key` | `string` | Yes | Business/customer code; maps ERP attributes |\n",
    "| `cst_firstname` | `string` | Yes | Raw given name |\n",
    "| `cst_lastname` | `string` | Yes | Raw surname |\n",
    "| `cst_marital_status` | `string` | Yes | Raw code S/M/etc |\n",
    "| `cst_gndr` | `string` | Yes | Raw gender code |\n",
    "| `cst_create_date` | `date` | Yes | Creation date as delivered |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409af6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = \"crm_cust_info\"\n",
    "inp = f\"{DATA_BASE}/cust_info.csv\"\n",
    "out = f\"{GCS_BASE}/bronze/{table}\"\n",
    "df = spark.read.csv(inp, header=True, schema=struct_schema(schemas[table]))\n",
    "df.write.mode(\"overwrite\").parquet(out)\n",
    "spark.read.parquet(out).createOrReplaceTempView(f\"bronze_crm_cust_info\")\n",
    "print(\"Wrote Parquet:\", out, \"| Rows:\", spark.read.parquet(out).count())\n",
    "spark.sql(\"SELECT * FROM bronze_crm_cust_info LIMIT 10\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23555e0",
   "metadata": {},
   "source": [
    "### Dataset: `crm_prd_info`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f31492",
   "metadata": {},
   "source": [
    "**Intent:** Raw, minimally-typed landing for reproducibility.\n",
    "\n",
    "| Column | Type | Nullable | Description |\n",
    "|---|---|---|---|\n",
    "| `prd_id` | `int` | Yes | Natural product ID |\n",
    "| `prd_key` | `string` | Yes | Composite key (category+sku) |\n",
    "| `prd_nm` | `string` | Yes | Product name |\n",
    "| `prd_cost` | `int` | Yes | Unit cost |\n",
    "| `prd_line` | `string` | Yes | Product line code M/R/S/T |\n",
    "| `prd_start_dt` | `timestamp` | Yes | Start timestamp |\n",
    "| `prd_end_dt` | `timestamp` | Yes | End timestamp (nullable) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ea48b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = \"crm_prd_info\"\n",
    "inp = f\"{DATA_BASE}/prd_info.csv\"\n",
    "out = f\"{GCS_BASE}/bronze/{table}\"\n",
    "df = spark.read.csv(inp, header=True, schema=struct_schema(schemas[table]))\n",
    "df.write.mode(\"overwrite\").parquet(out)\n",
    "spark.read.parquet(out).createOrReplaceTempView(f\"bronze_crm_prd_info\")\n",
    "print(\"Wrote Parquet:\", out, \"| Rows:\", spark.read.parquet(out).count())\n",
    "spark.sql(\"SELECT * FROM bronze_crm_prd_info LIMIT 10\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd6111d",
   "metadata": {},
   "source": [
    "### Dataset: `crm_sales_details`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5437cb3e",
   "metadata": {},
   "source": [
    "**Intent:** Raw, minimally-typed landing for reproducibility.\n",
    "\n",
    "| Column | Type | Nullable | Description |\n",
    "|---|---|---|---|\n",
    "| `sls_ord_num` | `string` | Yes | Order number / line identifier |\n",
    "| `sls_prd_key` | `string` | Yes | Product key references product |\n",
    "| `sls_cust_id` | `int` | Yes | Customer id references customer |\n",
    "| `sls_order_dt` | `int` | Yes | Integer date YYYYMMDD |\n",
    "| `sls_ship_dt` | `int` | Yes | Integer date YYYYMMDD |\n",
    "| `sls_due_dt` | `int` | Yes | Integer date YYYYMMDD |\n",
    "| `sls_sales` | `int` | Yes | Extended amount |\n",
    "| `sls_quantity` | `int` | Yes | Units sold |\n",
    "| `sls_price` | `int` | Yes | Unit price |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9a3db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = \"crm_sales_details\"\n",
    "inp = f\"{DATA_BASE}/sales_details.csv\"\n",
    "out = f\"{GCS_BASE}/bronze/{table}\"\n",
    "df = spark.read.csv(inp, header=True, schema=struct_schema(schemas[table]))\n",
    "df.write.mode(\"overwrite\").parquet(out)\n",
    "spark.read.parquet(out).createOrReplaceTempView(f\"bronze_crm_sales_details\")\n",
    "print(\"Wrote Parquet:\", out, \"| Rows:\", spark.read.parquet(out).count())\n",
    "spark.sql(\"SELECT * FROM bronze_crm_sales_details LIMIT 10\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48518c6",
   "metadata": {},
   "source": [
    "### Dataset: `erp_cust_az12`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700989b6",
   "metadata": {},
   "source": [
    "**Intent:** Raw, minimally-typed landing for reproducibility.\n",
    "\n",
    "| Column | Type | Nullable | Description |\n",
    "|---|---|---|---|\n",
    "| `cid` | `string` | Yes | ERP customer code |\n",
    "| `bdate` | `date` | Yes | Birthdate |\n",
    "| `gen` | `string` | Yes | Gender raw |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c06738",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = \"erp_cust_az12\"\n",
    "inp = f\"{DATA_BASE}/CUST_AZ12.csv\"\n",
    "out = f\"{GCS_BASE}/bronze/{table}\"\n",
    "df = spark.read.csv(inp, header=True, schema=struct_schema(schemas[table]))\n",
    "df.write.mode(\"overwrite\").parquet(out)\n",
    "spark.read.parquet(out).createOrReplaceTempView(f\"bronze_erp_cust_az12\")\n",
    "print(\"Wrote Parquet:\", out, \"| Rows:\", spark.read.parquet(out).count())\n",
    "spark.sql(\"SELECT * FROM bronze_erp_cust_az12 LIMIT 10\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88beb096",
   "metadata": {},
   "source": [
    "### Dataset: `erp_loc_a101`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ed4a41",
   "metadata": {},
   "source": [
    "**Intent:** Raw, minimally-typed landing for reproducibility.\n",
    "\n",
    "| Column | Type | Nullable | Description |\n",
    "|---|---|---|---|\n",
    "| `cid` | `string` | Yes | ERP customer code |\n",
    "| `cntry` | `string` | Yes | Country code/name |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0147ee63",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = \"erp_loc_a101\"\n",
    "inp = f\"{DATA_BASE}/LOC_A101.csv\"\n",
    "out = f\"{GCS_BASE}/bronze/{table}\"\n",
    "df = spark.read.csv(inp, header=True, schema=struct_schema(schemas[table]))\n",
    "df.write.mode(\"overwrite\").parquet(out)\n",
    "spark.read.parquet(out).createOrReplaceTempView(f\"bronze_erp_loc_a101\")\n",
    "print(\"Wrote Parquet:\", out, \"| Rows:\", spark.read.parquet(out).count())\n",
    "spark.sql(\"SELECT * FROM bronze_erp_loc_a101 LIMIT 10\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3d1e94",
   "metadata": {},
   "source": [
    "### Dataset: `erp_px_cat_g1v2`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed545629",
   "metadata": {},
   "source": [
    "**Intent:** Raw, minimally-typed landing for reproducibility.\n",
    "\n",
    "| Column | Type | Nullable | Description |\n",
    "|---|---|---|---|\n",
    "| `id` | `string` | Yes | Category id |\n",
    "| `cat` | `string` | Yes | Category |\n",
    "| `subcat` | `string` | Yes | Subcategory |\n",
    "| `maintenance` | `string` | Yes | Maintenance attribute |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb7559a",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = \"erp_px_cat_g1v2\"\n",
    "inp = f\"{DATA_BASE}/PX_CAT_G1V2.csv\"\n",
    "out = f\"{GCS_BASE}/bronze/{table}\"\n",
    "df = spark.read.csv(inp, header=True, schema=struct_schema(schemas[table]))\n",
    "df.write.mode(\"overwrite\").parquet(out)\n",
    "spark.read.parquet(out).createOrReplaceTempView(f\"bronze_erp_px_cat_g1v2\")\n",
    "print(\"Wrote Parquet:\", out, \"| Rows:\", spark.read.parquet(out).count())\n",
    "spark.sql(\"SELECT * FROM bronze_erp_px_cat_g1v2 LIMIT 10\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa604766",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- Bronze Parquet written under `GCS_BASE/bronze/*`; views `bronze_<table>` registered."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
